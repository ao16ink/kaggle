{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os, random, cv2\n\n\nimport keras as keras\nimport tensorflow as tf\nfrom keras.preprocessing import image\nfrom keras.applications.resnet import preprocess_input\nfrom keras.models import Sequential,Model\nfrom keras.layers import Input, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D,Lambda\nimport keras.backend as K\nfrom keras.optimizers import RMSprop,Adam\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_data = pd.read_csv(\"../input/siamese-split-data-csv/tr_data.csv\")\nte_data = pd.read_csv(\"../input/siamese-split-data-csv/te_data.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(a=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SiameseDataLoader(object):\n    def __init__(self, data_pd, sample_class_num , samples_per_class):\n        self._data_pd = data_pd\n        self._sample_class_num = sample_class_num\n        self._samples_per_class = samples_per_class\n        self._sample_file_names = self._get_samples()\n    \n\n    def _get_samples(self):\n        sample_file_names = []\n        ids = self._data_pd.landmark_id.unique()\n        P=0\n        for ID in range(len(ids)):\n            if ID%int(len(ids)/10)==0:\n                print(P*10,\"%\")\n                P+=1\n            same_label = self._data_pd.loc[self._data_pd.landmark_id == ids[ID]]\n            same_label = same_label.reset_index(drop=True)\n            sample_file_names_per_class = []\n            if len(same_label)>1:\n                for i in range(len(same_label)):\n                    num1 = str(same_label.id[i])[0]\n                    num2 = str(same_label.id[i])[1]\n                    num3 = str(same_label.id[i])[2]\n                    filename = str(same_label.id[i])\n                    filepath = \"../input/landmark-retrieval-2020/train/\" +num1+ \"/\" +num2+\"/\" +num3+ \"/\" + filename + \".jpg\"\n\n                    sample_file_names_per_class.append(filepath)\n                #print(\"a\",sample_file_names_per_class)\n                sample_file_names.append(sample_file_names_per_class)\n        #print(\"get\")\n        return sample_file_names\n    \n\n    \n    # positiveとnegativeの画像ペアを出力\n    def get_train_data(self):\n        pairs, labels = self._create_pairs(self._sample_file_names, self._samples_per_class)\n        tmp = np.array(Image.open(pairs[0][0]).convert('RGB'))\n        X1=[]\n        X2=[]\n        Y=[]\n        for pair, label in zip(pairs, labels):\n            img=np.array(Image.open(pair[0]).convert('RGB')).astype(\"int16\")\n            img=np.expand_dims(img, axis=0)\n            X1.append(img)\n            img=np.array(Image.open(pair[1]).convert('RGB')).astype(\"int16\")\n            img=np.expand_dims(img, axis=0)\n            X2.append(img)\n            Y.append(label)\n        return [X1,X2], Y\n    \n    def get_test_data(self, test_image_path, sample_class_num, samples_per_class):\n        pairs = []\n        #for sample_file_names_per_class in self._sample_file_names:\n        for j in range(sample_class_num):\n            sample_file_names_per_class = random.sample(sample_file_names, 1)[0]\n            \n            selected_files = random.sample(sample_file_names_per_class, samples_per_class)\n            for selected_file in selected_files:\n                pair = []\n                pair.append(test_image_path)\n                pair.append(selected_file)\n                pairs.append(pair)\n        X1=[]\n        X2=[]\n        for pair in pairs:\n            img=np.array(Image.open(pair[0]).convert('RGB')).astype(\"int16\")\n            img=np.expand_dims(img, axis=0)\n            X1.append(img)\n            img=np.array(Image.open(pair[1]).convert('RGB')).astype(\"int16\")\n            img=np.expand_di\n            X2.append(img)\n            \n        return [X1,X2]\n    \n    \n    def _create_pairs(self, sample_file_names, samples_per_class):\n        positive_pairs, positive_labels = self._create_positive_pairs(sample_file_names, samples_per_class)\n        negative_pairs, negative_labels = self._create_negative_pairs(sample_file_names, samples_per_class)\n        positive_pairs.extend(negative_pairs)\n        positive_labels.extend(negative_labels)\n        return positive_pairs, positive_labels\n    \n    # 同じラベルのペアを作成する\n    def _create_positive_pairs(self, sample_file_names, samples_per_class):\n        positive_pairs = []\n        labels=[]  \n        for j in range(self._sample_class_num):\n            sample_file_names_per_class = random.sample(sample_file_names, 1)[0]\n            for k in range(samples_per_class):\n                positive_pairs.append(random.sample(sample_file_names_per_class, 2))\n                labels.append(np.array([1.]))\n        #labels = np.array([1])*len(positive_pairs)\n        #print(len(positive_pairs))\n        return positive_pairs, labels\n    \n    # 異なるラベルのペアを作成する\n    def _create_negative_pairs(self, sample_file_names, samples_per_class):\n        negative_pairs = []\n        labels=[]\n        class_count =len(sample_file_names)\n            \n        for j in range(self._sample_class_num):\n            select = random.randint(0,class_count-1)\n            sample_file_names_per_class = sample_file_names[select]\n            \n            class_ids = list(range(class_count))\n            class_ids.remove(select)\n            for k in range(samples_per_class):\n                pair = []\n                pair.append(random.choice(sample_file_names[j]))\n                pair.append(random.choice(sample_file_names[random.choice(class_ids)]))\n                negative_pairs.append(pair)\n                labels.append(np.array([0.]))\n        #labels = np.array([0])*len(negative_pairs)\n        #print(labels)\n        #print(len(negative_pairs))\n        return negative_pairs, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loader=SiameseDataLoader(te_data,50,2)\nX, y = loader.get_train_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM=98\nprint(y[NUM])\nplt.subplots(figsize=(10,10))\nplt.subplot(121)\n\nplt.imshow(X[0][NUM][0].astype(\"int16\"))\nplt.subplot(122)\nplt.imshow(X[1][NUM][0].astype(\"int16\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_tensor = Input(shape=(None,None, 3))\nresnet101=tf.keras.applications.ResNet101(\n    include_top=False, weights='imagenet',input_tensor=input_tensor\n)\nAVP = Sequential(GlobalAveragePooling2D())\nEncoder=Model(inputs=resnet101.input,outputs=AVP(resnet101.output))\nEncoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=X[0][0].astype(\"float32\")\n#x = np.expand_dims(x, axis=0)\nEncoder.predict(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in Encoder.layers[:313]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SiameseNet(object):\n    def __init__(self,encoder):\n        Encoder=encoder\n        \n        input_a = Input(shape=[None,None,3])\n        input_b = Input(shape=[None,None,3])\n        input_a = tf.cast(input_a, tf.float32)\n        input_b = tf.cast(input_b, tf.float32)\n        \n        processed_a = Encoder(input_a)\n        processed_b = Encoder(input_b)\n        #print(\"b\",processed_b)\n        distance = Lambda(self._euclidean_distance, output_shape=(2,2))([processed_a, processed_b])#self._eucl_dist_output_shape\n        #print(\"d\",distance)\n        self._model = Model(inputs=[input_a, input_b], outputs=distance)\n\n    def _euclidean_distance(self, vects):\n        x, y = vects\n        #print(\"_eu\",vects)\n        distance = K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n        #print(\"_eu_\",distance)\n        return distance\n\n    def _eucl_dist_output_shape(self, shapes):\n        shape1, shape2 = shapes\n        #print(\"_e\",shape1[0])\n        return (shape1[0], 1)\n\n    def get_model(self):\n        return self._model\n    \ndef contrastive_loss(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    #print(\"a\",y_true, y_pred)\n    margin = 1\n    loss=K.mean(y_true*K.square(y_pred) + (1 - y_true)*K.square(K.maximum(margin - y_pred, 0)))\n    #print(\"L\",loss)\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"loader_prepare\")\nloader_train = SiameseDataLoader(tr_data,150,1)\nprint(\"loader_train:ok\")\nloader_test = SiameseDataLoader(te_data,75,1)\nprint(\"loader_test:ok\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adam not works well for Siamese net\noptim = RMSprop(decay=1e-4)\n#optim = Adam(lr=0.0001, decay=1e-4, amsgrad=True)\nsiamese = SiameseNet(Encoder).get_model()\nsiamese.compile(optimizer=optim, loss=contrastive_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#siamese.load_weights('./weights_I709_L0.06329984217882156.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iterations = 1000000\nmin_loss = 9999\nmin_iter = -1\nprint(\"start\")\nfor iteration in range(iterations):\n    X = []\n    y = []\n    X, y = loader_train.get_train_data()\n    #print(\"X\",len(X[0]))\n    #print(\"y\",len(y[0]))\n    loss_train = siamese.train_on_batch(X,y)\n    print(iteration+1,\",\", end=\"\")\n    if (iteration+1)%5 == 0:\n        X = []\n        y = []\n        X, y = loader_test.get_train_data()\n        loss_val = siamese.evaluate(X, y,verbose=0)\n        if loss_val < min_loss:\n            min_iter = iteration\n            min_loss = loss_val\n            siamese.save_weights('weights_M1_I'+str(min_iter)+'_L'+str(min_loss)+'.h5', True)\n        print('///////////loss@' + str(iteration+1) + ' = ' + str(loss_train) + ',' + str(loss_val) + ' (' + str(min_loss) + '@' + str(min_iter) + ')')\n    keras.backend.clear_session()\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_model = SiameseNet(Encoder).get_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_model.load_weights('./weights_M1_I469_L0.3352832496166229.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Decoder = Model(inputs=load_model.get_layer(\"functional_1\").input,\n                                 outputs=load_model.get_layer(\"functional_1\").output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=X[0][0].astype(\"float32\")\nf=Decoder(x).numpy().copy()\nfor i in range(len(f[0])):\n    print(f[0][i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyModel(tf.keras.Model):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.model = Decoder\n    \n    @tf.function(input_signature=[\n      tf.TensorSpec(shape=[None, None, 3], dtype=tf.uint8, name='input_image')\n    ])\n    def call(self, im):\n        output_tensors = {}\n        im=tf.cast(im, tf.float32)\n\n        extracted_features = self.model(tf.convert_to_tensor([im], dtype=tf.float32))[0]\n        output_tensors['global_descriptor'] = tf.identity(extracted_features, name='global_descriptor')\n        return output_tensors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model=MyModel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"served_function = my_model.call\ntf.saved_model.save(\n      my_model, export_dir=\"./my_model\", signatures={'serving_default': served_function})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from zipfile import ZipFile\n\nwith ZipFile('submission.zip','w') as zip:           \n    zip.write('./my_model/saved_model.pb', arcname='saved_model.pb') \n    zip.write('./my_model/variables/variables.data-00000-of-00001', arcname='variables/variables.data-00000-of-00001') \n    zip.write('./my_model/variables/variables.index', arcname='variables/variables.index') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nmnist = tf.keras.datasets.mnist\n \n(x_train, y_train),(x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\nprint(len(x_train[0]), len(x_test[0]))\nprint(x_train)\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n \nmodel.fit(x_train, y_train, epochs=5)\nmodel.evaluate(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}